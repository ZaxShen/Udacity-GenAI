{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e672bb19",
      "metadata": {},
      "source": [
        "# Exercise: Teach an LLM to Spell with Group Relative Policy Optimization (GRPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e01691a",
      "metadata": {},
      "source": [
        "Large language models (LLMs) are notoriously bad at spelling. This is partly because tokenizers break words into smaller pieces, so the model learns about sub-word units rather than whole words and their spellings.\n",
        "\n",
        "In this exercise, you'll use Group Relative Policy Optimization (GRPO) and a technique called Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA) to teach a small LLM how to spell words. This is a classic example of teaching a model a new skill that isn't well-represented in its pre-training data.\n",
        "\n",
        "## What you'll do in this notebook\n",
        "\n",
        "1.  **Setup**: Import libraries and configure the environment.\n",
        "2.  **Load the tokenizer and base model**: Use a small, instruction-tuned model as our starting point.\n",
        "3.  **Create the dataset**: Generate a simple dataset of words and their correct spellings.\n",
        "4.  **Evaluate the base model**: Test the model's spelling ability *before* fine-tuning to establish a baseline.\n",
        "5.  **Configure LoRA and train**: Attach a LoRA adapter to the model and fine-tune it on the spelling dataset.\n",
        "6.  **Evaluate the fine-tuned model**: Test the model again to see if its spelling has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d04085e7",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97437029",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Setup imports\n",
        "# No changes needed in this cell\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Use GPU, MPS, or CPU, in that order of preference\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")  # Apple Silicon\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f0a0d7",
      "metadata": {},
      "source": [
        "## Step 1. Load the tokenizer and base model\n",
        "\n",
        "The model `HuggingFaceTB/SmolLM2-135M-Instruct` is a small, instruction-tuned model that's suitable for this exercise. It has 135 million parameters, making it lightweight and efficient for fine-tuning. It's not the most powerful model, but it's a good choice for demonstrating the concepts of SFT and PEFT with LoRA, especially on a CPU or limited GPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8028ac1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters (total): 134515008\n"
          ]
        }
      ],
      "source": [
        "# Student task: Load the model and tokenizer, and copy the model to the device.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "# See: https://huggingface.co/docs/transformers/en/models\n",
        "# See: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
        "\n",
        "# Model ID for SmolLM2-135M-Instruct\n",
        "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Copy the model to the device (GPU, MPS, or CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Model parameters (total):\", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6665787",
      "metadata": {},
      "source": [
        "## Step 2. Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "46de84a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "# fmt: off\n",
        "ALL_WORDS = [\n",
        "    \"idea\", \"glow\", \"rust\", \"maze\", \"echo\", \"wisp\", \"veto\", \"lush\", \"gaze\", \"knit\", \"fume\", \"plow\",\n",
        "    \"void\", \"oath\", \"grim\", \"crisp\", \"lunar\", \"fable\", \"quest\", \"verge\", \"brawn\", \"elude\", \"aisle\",\n",
        "    \"ember\", \"crave\", \"ivory\", \"mirth\", \"knack\", \"wryly\", \"onset\", \"mosaic\", \"velvet\", \"sphinx\",\n",
        "    \"radius\", \"summit\", \"banner\", \"cipher\", \"glisten\", \"mantle\", \"scarab\", \"expose\", \"fathom\",\n",
        "    \"tavern\", \"fusion\", \"relish\", \"lantern\", \"enchant\", \"torrent\", \"capture\", \"orchard\", \"eclipse\",\n",
        "    \"frescos\", \"triumph\", \"absolve\", \"gossipy\", \"prelude\", \"whistle\", \"resolve\", \"zealous\",\n",
        "    \"mirage\", \"aperture\", \"sapphire\",\n",
        "]\n",
        "# fmt: on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbeab6e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\ntriumph\\n\\nSpelling:\\n',\n",
              " 'completion': 'T-R-I-U-M-P-H.',\n",
              " 'word': 'triumph',\n",
              " 'spelling': 'T-R-I-U-M-P-H'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student Task: Create a Hugging Face Dataset with the prompt that asks the model to spell the word\n",
        "# with hyphens between the letters.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        yield {\n",
        "            # We will use the GRPOTrainer which expects to receieve formatted prompts\n",
        "            # to pass to the LLM\n",
        "            # https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "            \"prompt\": (\n",
        "                f\"You spell words with hyphens between the letters like this W-O-R-D.\\nWord:\\n{word}\\n\\n\"\n",
        "                + \"Spelling:\\n\"\n",
        "            ),\n",
        "            # Before using GRPOTrainer, will run a few epochs of supervised-fine tuning (SFT)\n",
        "            # which can be useful to give an initial nudge to the model. Thus we need to provide\n",
        "            # the gold standard answer.\n",
        "            # See the documentation for more details:\n",
        "            # https://huggingface.co/docs/trl/en/sft_trainer#expected-dataset-type-and-format\n",
        "            \"completion\": \"-\".join(word).upper() + \".\",\n",
        "            # GRPOTrainer does not expect a completion, but we can add extra columns to our dataset\n",
        "            # that our reward functions will use to grade the completions provided by the LLM.\n",
        "            \"word\": word,\n",
        "            \"spelling\": \"-\".join(word).upper(),\n",
        "        }\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "ds = ds.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "# Show the first item of the train split\n",
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6a9436",
      "metadata": {},
      "source": [
        "## Step 3. Evaluate the base model\n",
        "\n",
        "Before we fine-tune the model, let's see how it performs on the spelling task. We'll create a helper function to generate a spelling for a given word and compare it to the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6581c243",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a helper function that will help us visualize the performance of the model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def check_spelling(\n",
        "    model, tokenizer, prompt: str, actual_spelling: str, max_new_tokens: int = 20\n",
        ") -> (str, str):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    gen = model.generate(\n",
        "        **inputs, max_new_tokens=max_new_tokens, use_cache=False\n",
        "    )  # No parameters = greedy search\n",
        "    output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the generated spelling from the full output string\n",
        "    proposed_spelling = output.split(\"Spelling:\\n\")[-1].strip().split(\"\\n\")[0].strip()\n",
        "\n",
        "    # strip any whitepsace from the actual spelling\n",
        "    actual_spelling = actual_spelling.strip()\n",
        "\n",
        "    print(\n",
        "        f\"Proposed: {proposed_spelling} | Actual: {actual_spelling} \"\n",
        "        f\"| Matches: {'✅' if proposed_spelling == actual_spelling else '❌'}\"\n",
        "    )\n",
        "\n",
        "    # Remove hyphens for a character-by-character comparison\n",
        "    proposed_spelling = proposed_spelling.replace(\"-\", \"\")\n",
        "    actual_spelling = actual_spelling.replace(\"-\", \"\")\n",
        "\n",
        "    # Calculate the proportion of the spelling that was correct\n",
        "    num_correct = sum(1 for a, b in zip(actual_spelling, proposed_spelling) if a == b)\n",
        "\n",
        "    return num_correct / len(actual_spelling)  # Return proportion correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7642646c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: trium | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
            "Proposed: sapp | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
            "Proposed: expose | Actual: E-X-P-O-S-E | Matches: ❌\n",
            "Proposed: fres | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
            "Proposed: wisp | Actual: W-I-S-P | Matches: ❌\n",
            "Proposed: mi-er-ge | Actual: M-I-R-A-G-E | Matches: ❌\n",
            "Proposed: ivory | Actual: I-V-O-R-Y | Matches: ❌\n",
            "Proposed: onset | Actual: O-N-S-E-T | Matches: ❌\n",
            "Proposed: elude | Actual: E-L-U-D-E | Matches: ❌\n",
            "Proposed: sphinx | Actual: S-P-H-I-N-X | Matches: ❌\n",
            "Proposed: brawn | Actual: B-R-A-W-N | Matches: ❌\n",
            "Proposed: goss | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
            "Proposed: enchant | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
            "Proposed: tavern | Actual: T-A-V-E-R-N | Matches: ❌\n",
            "Proposed: whistle | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
            "Proposed: W-O-R-D | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
            "Proposed: echo | Actual: E-C-H-O | Matches: ❌\n",
            "Proposed: mirth | Actual: M-I-R-T-H | Matches: ❌\n",
            "Proposed: cris | Actual: C-R-I-S-P | Matches: ❌\n",
            "Proposed: zeal | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
            "0.0/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Student task: Evaluate the base model's spelling ability\n",
        "# We expect it to perform poorly, as it hasn't been trained for this task.\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    spelling = example[\"spelling\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=spelling,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c6563f",
      "metadata": {},
      "source": [
        "As expected, the base model is terrible at spelling. It mostly just repeats the word back. Now, let's fine-tune it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e7ef15",
      "metadata": {},
      "source": [
        "## Step 4. Configure LoRA and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403a39e8",
      "metadata": {},
      "source": [
        "Let’s attach a LoRA adapter to the base model. We use a LoRA config so only a tiny fraction of parameters are trainable. Read more here: [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d1b8d596",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable params BEFORE: 134,515,008 / 134,515,008 (100.00%)\n",
            "Trainable params AFTER: 3,686,400 / 138,201,408 (2.67%)\n"
          ]
        }
      ],
      "source": [
        "# Student task: Configure LoRA for a causal LM and wrap the model with get_peft_model\n",
        "# Complete the sections with **********\n",
        "\n",
        "# Print how many params are trainable at first\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params BEFORE: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")\n",
        "\n",
        "# See: https://huggingface.co/docs/peft/package_reference/lora\n",
        "lora_config = LoraConfig(\n",
        "    r=64,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
        "    lora_alpha=16,        # LoRA scaling factor.\n",
        "    lora_dropout=0.05,      # Dropout probability for LoRA layers.\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",         # Causal Language Modeling.\n",
        ")\n",
        "# Wrap the base model with get_peft_model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "\n",
        "# Print the number of trainable parameters after applying LoRA\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params AFTER: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30c5e91b",
      "metadata": {},
      "source": [
        "Now let’s set the training arguments. We'll use `SFTConfig` from the TRL library, which is a wrapper around the standard `TrainingArguments`. We keep epochs, batch size, and sequence length modest to finish training quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9341ba79",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zacks/Git/GitHub/Udacity/Udacity-GenAI/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:30, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Num Tokens</th>\n",
              "      <th>Mean Token Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.076600</td>\n",
              "      <td>0.863844</td>\n",
              "      <td>2.359811</td>\n",
              "      <td>6833.000000</td>\n",
              "      <td>0.683468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.528600</td>\n",
              "      <td>0.744596</td>\n",
              "      <td>2.079863</td>\n",
              "      <td>13603.000000</td>\n",
              "      <td>0.730847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.426200</td>\n",
              "      <td>0.735462</td>\n",
              "      <td>2.038377</td>\n",
              "      <td>20407.000000</td>\n",
              "      <td>0.757392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zacks/Git/GitHub/Udacity/Udacity-GenAI/.venv/lib/python3.13/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: T-I-R-U-M-P-H. | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
            "Proposed: S-A-P-I-C-R-H. | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
            "Proposed: E-X-P-S-E-T. | Actual: E-X-P-O-S-E | Matches: ❌\n",
            "Proposed: F-S-R-E-C-O-S. | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
            "Proposed: W-I-P-S. | Actual: W-I-S-P | Matches: ❌\n",
            "Proposed: M-I-R-E-G. | Actual: M-I-R-A-G-E | Matches: ❌\n",
            "Proposed: I-V-O-R-Y. | Actual: I-V-O-R-Y | Matches: ❌\n",
            "Proposed: O-N-S-H-O-R-D. | Actual: O-N-S-E-T | Matches: ❌\n",
            "Proposed: E-L-E-U-D. | Actual: E-L-U-D-E | Matches: ❌\n",
            "Proposed: S-P-H-I-N-X. | Actual: S-P-H-I-N-X | Matches: ❌\n",
            "Proposed: B-R-A-N-Y. | Actual: B-R-A-W-N | Matches: ❌\n",
            "Proposed: G-S-O-P-I-Y. | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
            "Proposed: E-N-C-H-A-N-T. | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
            "Proposed: T-A-A-N-R. | Actual: T-A-V-E-R-N | Matches: ❌\n",
            "Proposed: W-H-I-S-E. | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
            "Proposed: C-U-P-H-E-R. | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
            "Proposed: E-C-H-O-R-E. | Actual: E-C-H-O | Matches: ❌\n",
            "Proposed: M-I-R-T. | Actual: M-I-R-T-H | Matches: ❌\n",
            "Proposed: C-R-I-S-P. | Actual: C-R-I-S-P | Matches: ❌\n",
            "Proposed: Z-E-A-L-O-U-S. | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
            "13.51309523809524/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Train the model for a few epochs using SFT before GRPO as in certain cases\n",
        "# they can work together synergystically.\n",
        "# See: https://arxiv.org/html/2507.08267v1\n",
        "# No changes needed here\n",
        "\n",
        "output_dir = \"data/model\"\n",
        "\n",
        "training_args = SFTConfig(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5 * 1e-4,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[],\n",
        "    fp16=False,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"test\"],\n",
        "    args=training_args,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    spelling = example[\"spelling\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=spelling,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d995e64",
      "metadata": {},
      "source": [
        "The number of words has slightly increased. Let's try training using GRPO now.\n",
        "\n",
        "First let's create some reward functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd8e58bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Student Task: Create a helper function proportion_correct that takes a word and\n",
        "# a proposed spelling from the LLM and returns a score where every matched character\n",
        "# adds +1 and every  mismatched character subtracts 1 from the reward--including the\n",
        "# hyphens.\n",
        "# TODO: Replace occurences of **********\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def proportion_correct(word, proposed_spelling):\n",
        "    correct_spelling = \"-\".join(word).upper()\n",
        "\n",
        "    score = 0.0\n",
        "\n",
        "    # Pad to the same length to handle extra characters\n",
        "    max_len = max(len(correct_spelling), len(proposed_spelling))\n",
        "    proposed_spelling_padded = proposed_spelling.ljust(max_len, \" \")\n",
        "    correct_spelling_padded = correct_spelling.ljust(max_len, \" \")\n",
        "\n",
        "    for a, b in zip(correct_spelling_padded, proposed_spelling_padded):\n",
        "        # Add 1 for matched characters, and subtract one for mismatched\n",
        "        if a == b:\n",
        "            score += 1\n",
        "        else:\n",
        "            score -= 1\n",
        "\n",
        "\n",
        "    return score / (\n",
        "        len(correct_spelling)\n",
        "    )  # Normalize by length of spelling, including dashes\n",
        "\n",
        "\n",
        "assert proportion_correct(\"hello\", \"H-E-L-L-O\") == 9 / 9\n",
        "assert proportion_correct(\"hello\", \"H-E-L-\") == 3 / 9\n",
        "assert proportion_correct(\"hello\", \"H-E-L-L-O!\") == 8 / 9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "10e1457a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: hello -> H-E-L-L-O\n",
            "Spelling mean and std: 0.741 +/- 0.292\n"
          ]
        }
      ],
      "source": [
        "# Create a `reward_spelling` function that receives a batch of completions and the associated word values\n",
        "# No changes needed here\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def reward_spelling(completions, word, **kwargs):\n",
        "    \"\"\"Reward function that rewards completions with more unique letters.\"\"\"\n",
        "\n",
        "    completion_strings = [\n",
        "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
        "    ]\n",
        "    words = [w for w in word]\n",
        "\n",
        "    rewards = [proportion_correct(w, c) for w, c in zip(words, completion_strings)]\n",
        "\n",
        "    # When training, GRPO will pass multiple completions and words to this function.\n",
        "    # We print just the first one to observe what is happening under the hood.\n",
        "    print(\"=====\")\n",
        "    print(\n",
        "        \"Completion example first line:\",\n",
        "        words[0],\n",
        "        \"->\",\n",
        "        completion_strings[0].strip().split(\"\\n\")[0].strip(),\n",
        "    )\n",
        "    print(f\"Spelling mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\")\n",
        "    return rewards\n",
        "\n",
        "\n",
        "assert reward_spelling(\n",
        "    completions=[\n",
        "        \"H-E-L-L-O\",\n",
        "        \"H-E-L-\",\n",
        "        \"H-E-L-L-O!\",\n",
        "    ],\n",
        "    word=[\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "    ],\n",
        ") == [1, 3 / 9, 8 / 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9b98d1ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Letter-dash-letter rewards mean and std: 0.333 +/- 0.471\n"
          ]
        }
      ],
      "source": [
        "# Student task: Create a reward of 1.0 for completions starting with a string\n",
        "# formatted like X-Y-Z else return 0.0\n",
        "# TODO: Replace sections marked with **********\n",
        "\n",
        "\n",
        "def reward_response_in_form_of_letter_dash_letter(completions, word, **kwargs):\n",
        "    \"\"\"Reward function that gives a bonus for completions in the form of LETTER-DASH-LETTER.\"\"\"\n",
        "    pattern = re.compile(r\"^([A-Z]-)+[A-Z]\")  # Pattern for LETTER-DASH-LETTER\n",
        "\n",
        "    words = [w for w in word]\n",
        "\n",
        "    # Normalize the completions, taking the first line and removing extra whitespace\n",
        "    completion_strings = [\n",
        "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
        "    ]\n",
        "\n",
        "    # Create a list of rewards corresponding to completions\n",
        "    # Each completion that matches the pattern should receive 1.0,\n",
        "    # else 0.0\n",
        "    rewards = [\n",
        "        1.0 if pattern.match(c) else 0.0 for w, c in zip(words, completion_strings)\n",
        "    ]\n",
        "\n",
        "    # <<< START COMPLETION SECTION\n",
        "    rewards = [\n",
        "        1.0 if pattern.match(c) else 0.0 for w, c in zip(words, completion_strings)\n",
        "    ]\n",
        "    # >>> END COMPLETION SECTION\n",
        "\n",
        "    print(\n",
        "        f\"Letter-dash-letter rewards mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\"\n",
        "    )\n",
        "    return rewards\n",
        "\n",
        "\n",
        "assert reward_response_in_form_of_letter_dash_letter(\n",
        "    completions=[\n",
        "        \"H-E-L-L-O\",\n",
        "        \"hello\",\n",
        "        \"Hi!\",\n",
        "    ],\n",
        "    word=[\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "    ],\n",
        ") == [1, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f8a9d1e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zacks/Git/GitHub/Udacity/Udacity-GenAI/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: mirth -> M-I-R-H.\n",
            "Spelling mean and std: 0.107 +/- 0.263\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 04:04, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.021000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.028900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>-0.010100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.057500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>-0.028100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>-0.022300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>-0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.030500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>-0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>-0.053600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>-0.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>-0.050500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>-0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.036300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>-0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>-0.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.020200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>-0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>-0.020900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.017600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>-0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>-0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>-0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>-0.023800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>-0.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.045000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.031100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>-0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>-0.025100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.018400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: mantle -> M-T-N-R-I-L.\n",
            "Spelling mean and std: 0.068 +/- 0.168\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-M-U-T-I.\n",
            "Spelling mean and std: -0.114 +/- 0.562\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-E-U-R-A.\n",
            "Spelling mean and std: 0.301 +/- 0.285\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-U-H-Y.\n",
            "Spelling mean and std: 0.342 +/- 0.335\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-I-S-S-E-L.\n",
            "Spelling mean and std: 0.137 +/- 0.290\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-B-Y-N.\n",
            "Spelling mean and std: -0.056 +/- 0.203\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-W-N.\n",
            "Spelling mean and std: 0.222 +/- 0.266\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-P-A-Z-I-R-H.\n",
            "Spelling mean and std: 0.123 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-H-O-M-C.\n",
            "Spelling mean and std: -0.106 +/- 0.128\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-O-R-I-D.\n",
            "Spelling mean and std: 0.014 +/- 0.287\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-H-A-T.\n",
            "Spelling mean and std: -0.104 +/- 0.297\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: crisp -> C-I-S-R-P.\n",
            "Spelling mean and std: 0.306 +/- 0.496\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-E-R-L-U-F.\n",
            "Spelling mean and std: 0.146 +/- 0.291\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-S-O-R-E.\n",
            "Spelling mean and std: 0.166 +/- 0.349\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: glow -> G-L-O-V-O.\n",
            "Spelling mean and std: -1.029 +/- 2.614\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: knit -> W-I-N-T.\n",
            "Spelling mean and std: 0.141 +/- 0.396\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G.\n",
            "Spelling mean and std: 0.308 +/- 0.344\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M-I-A-R-E.\n",
            "Spelling mean and std: 0.239 +/- 0.240\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-O-T.\n",
            "Spelling mean and std: 0.190 +/- 0.291\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-R-O.\n",
            "Spelling mean and std: 0.500 +/- 0.371\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-I-C-S.\n",
            "Spelling mean and std: -0.048 +/- 0.331\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-N.\n",
            "Spelling mean and std: 0.233 +/- 0.270\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S.\n",
            "Spelling mean and std: 0.085 +/- 0.116\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-M.\n",
            "Spelling mean and std: 0.139 +/- 0.138\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-I-F-S-H.\n",
            "Spelling mean and std: 0.154 +/- 0.326\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-E-U-D.\n",
            "Spelling mean and std: 0.285 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-I-S-U-R-B.\n",
            "Spelling mean and std: 0.068 +/- 0.363\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-n-S-h-R-D.\n",
            "Spelling mean and std: 0.490 +/- 0.329\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-R-Y.\n",
            "Spelling mean and std: 0.216 +/- 0.231\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-L-U-S-E.\n",
            "Spelling mean and std: 0.315 +/- 0.228\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-M-I-N.\n",
            "Spelling mean and std: 0.054 +/- 0.206\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-N-W.\n",
            "Spelling mean and std: 0.385 +/- 0.302\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-I-R-H.\n",
            "Spelling mean and std: 0.152 +/- 0.096\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-I-A.\n",
            "Spelling mean and std: 0.449 +/- 0.253\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: velvet -> V-L-E-V-T.\n",
            "Spelling mean and std: 0.384 +/- 0.467\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-B-L-E.\n",
            "Spelling mean and std: 0.396 +/- 0.214\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-E-R-T-E.\n",
            "Spelling mean and std: 0.232 +/- 0.693\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-T-P-L-E.\n",
            "Spelling mean and std: -0.189 +/- 1.013\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R.\n",
            "Spelling mean and std: 0.159 +/- 0.308\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-S-R-O-C-S.\n",
            "Spelling mean and std: -0.096 +/- 0.426\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U-R-E.\n",
            "Spelling mean and std: 0.389 +/- 0.229\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-O-H-M-E.\n",
            "Spelling mean and std: 0.240 +/- 0.391\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-H-R-A-K-B.\n",
            "Spelling mean and std: 0.196 +/- 0.168\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-O-T.\n",
            "Spelling mean and std: -0.120 +/- 0.291\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-O-U-D.\n",
            "Spelling mean and std: 0.181 +/- 0.123\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-O-R-E.\n",
            "Spelling mean and std: 0.135 +/- 0.315\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-L-E.\n",
            "Spelling mean and std: 0.575 +/- 0.338\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-U-R-I-M-P-H.\n",
            "Spelling mean and std: 0.202 +/- 0.261\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-N-S-E.\n",
            "Spelling mean and std: 0.000 +/- 0.175\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-S-C-E-L-U-C.\n",
            "Spelling mean and std: 0.058 +/- 0.206\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E-A-R.\n",
            "Spelling mean and std: 0.195 +/- 0.328\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-E-R.\n",
            "Spelling mean and std: 0.165 +/- 0.326\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-E-L-O-U-S.\n",
            "Spelling mean and std: -0.201 +/- 0.506\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-E.\n",
            "Spelling mean and std: 0.311 +/- 0.274\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.379 +/- 0.383\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-L-T.\n",
            "Spelling mean and std: 0.023 +/- 0.082\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-A-B-I-R-H.\n",
            "Spelling mean and std: 0.361 +/- 0.412\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> L-A-N-N-T.\n",
            "Spelling mean and std: 0.212 +/- 0.251\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-A-P-I-S.\n",
            "Spelling mean and std: 0.110 +/- 0.212\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-H-R-T.\n",
            "Spelling mean and std: 0.372 +/- 0.212\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> W-I-L-T.\n",
            "Spelling mean and std: 0.006 +/- 0.307\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-O-W.\n",
            "Spelling mean and std: 0.484 +/- 0.330\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-S-O-P-I-N-Y.\n",
            "Spelling mean and std: 0.387 +/- 0.156\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-P-L-E.\n",
            "Spelling mean and std: 0.245 +/- 0.448\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-Sw-I-R-A.\n",
            "Spelling mean and std: 0.239 +/- 0.358\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-A-V-S-E.\n",
            "Spelling mean and std: 0.253 +/- 0.347\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-R-U-M-I-P-H.\n",
            "Spelling mean and std: 0.269 +/- 0.200\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-S-L-I-R.\n",
            "Spelling mean and std: 0.396 +/- 0.363\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-O-R.\n",
            "Spelling mean and std: 0.273 +/- 0.422\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-U-U-R.\n",
            "Spelling mean and std: 0.153 +/- 0.273\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-O-M-S.\n",
            "Spelling mean and std: 0.136 +/- 0.218\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-L-D-U-N.\n",
            "Spelling mean and std: 0.371 +/- 0.304\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-U-S.\n",
            "Spelling mean and std: 0.194 +/- 0.590\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-O.\n",
            "Spelling mean and std: 0.224 +/- 0.254\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-R-A-D.\n",
            "Spelling mean and std: 0.163 +/- 0.205\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-E-M-E.\n",
            "Spelling mean and std: -0.026 +/- 1.385\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-U-T.\n",
            "Spelling mean and std: 0.192 +/- 0.245\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-Y-R-Y.\n",
            "Spelling mean and std: 0.167 +/- 0.342\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M-I-R-A-G-E.\n",
            "Spelling mean and std: 0.372 +/- 0.309\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-H-O-M-T.\n",
            "Spelling mean and std: 0.130 +/- 0.114\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: veto -> V-E-T-O.\n",
            "Spelling mean and std: 0.547 +/- 0.316\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-R-I-S-T.\n",
            "Spelling mean and std: 0.414 +/- 0.352\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-V-E.\n",
            "Spelling mean and std: 0.341 +/- 0.422\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: glow -> G-L-O-V-H.\n",
            "Spelling mean and std: 0.385 +/- 0.262\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-U-R-E.\n",
            "Spelling mean and std: 0.019 +/- 0.148\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-E-D.\n",
            "Spelling mean and std: 0.194 +/- 0.187\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-L-E.\n",
            "Spelling mean and std: 0.497 +/- 0.271\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-U-S.\n",
            "Spelling mean and std: -0.040 +/- 0.509\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: rust -> R-UST.\n",
            "Spelling mean and std: 0.357 +/- 0.440\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-U-C-Y.\n",
            "Spelling mean and std: 0.548 +/- 0.417\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-L-S.\n",
            "Spelling mean and std: 0.057 +/- 0.305\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: lunar -> L-U-R-N-E.\n",
            "Spelling mean and std: 0.292 +/- 0.207\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-S-I-E-R.\n",
            "Spelling mean and std: 0.112 +/- 0.365\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-C-U-L-E.\n",
            "Spelling mean and std: 0.072 +/- 0.086\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-H-A-M-T.\n",
            "Spelling mean and std: -0.023 +/- 0.136\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-H-M.\n",
            "Spelling mean and std: 0.411 +/- 0.298\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-N-R-E.\n",
            "Spelling mean and std: 0.125 +/- 0.231\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-I-P-S.\n",
            "Spelling mean and std: 0.321 +/- 0.243\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.268 +/- 0.481\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.453 +/- 0.393\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-I-L-O-R.\n",
            "Spelling mean and std: 0.285 +/- 0.195\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-I-L-E.\n",
            "Spelling mean and std: 0.216 +/- 0.180\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> W-I-T-E-N.\n",
            "Spelling mean and std: 0.143 +/- 0.441\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-E-R.\n",
            "Spelling mean and std: 0.414 +/- 0.370\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-E.\n",
            "Spelling mean and std: 0.270 +/- 0.172\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-S-R-U-C-S.\n",
            "Spelling mean and std: 0.269 +/- 0.228\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-E-R-T-U-R-E.\n",
            "Spelling mean and std: 0.248 +/- 0.201\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-s-H-O-P-I-X.\n",
            "Spelling mean and std: 0.198 +/- 0.204\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-L-A-O-U-S.\n",
            "Spelling mean and std: 0.451 +/- 0.339\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-E-O-T.\n",
            "Spelling mean and std: 0.143 +/- 0.535\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-H-I-R-E.\n",
            "Spelling mean and std: 0.307 +/- 0.291\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E-R.\n",
            "Spelling mean and std: 0.338 +/- 0.360\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: frescos -> F-S-R-E-C-S.\n",
            "Spelling mean and std: 0.363 +/- 0.357\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-S-I-L-A.\n",
            "Spelling mean and std: 0.165 +/- 0.473\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-V-E-T.\n",
            "Spelling mean and std: 0.547 +/- 0.304\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: glow -> G-O-L-V-O.\n",
            "Spelling mean and std: 0.429 +/- 0.535\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> H-W-I-C-E.\n",
            "Spelling mean and std: -0.069 +/- 0.270\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-Y.\n",
            "Spelling mean and std: 0.306 +/- 0.227\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-I-M-H-O.\n",
            "Spelling mean and std: 0.176 +/- 0.226\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-E-R-U-V-E.\n",
            "Spelling mean and std: 0.135 +/- 0.179\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-K-R.\n",
            "Spelling mean and std: 0.333 +/- 0.248\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-R-I-U-M-P-H.\n",
            "Spelling mean and std: 0.529 +/- 0.204\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-B-E.\n",
            "Spelling mean and std: 0.200 +/- 0.187\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-S-N-T.\n",
            "Spelling mean and std: 0.060 +/- 0.188\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-R-N.\n",
            "Spelling mean and std: 0.414 +/- 0.349\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-T.\n",
            "Spelling mean and std: 0.146 +/- 0.135\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-h-I-N-X.\n",
            "Spelling mean and std: 0.519 +/- 0.307\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-I-T.\n",
            "Spelling mean and std: 0.003 +/- 0.243\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-E-R-T-U-R.\n",
            "Spelling mean and std: 0.208 +/- 0.114\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-E-R.\n",
            "Spelling mean and std: 0.169 +/- 0.316\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-E-U-D.\n",
            "Spelling mean and std: 0.542 +/- 0.374\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-O-R-D.\n",
            "Spelling mean and std: 0.309 +/- 0.275\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: enchant -> E-N-C-H-P-A-T.\n",
            "Spelling mean and std: 0.144 +/- 0.330\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-S-R-I-Z.\n",
            "Spelling mean and std: 0.007 +/- 0.197\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> R-I-G-M.\n",
            "Spelling mean and std: 0.260 +/- 0.197\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-I-C.\n",
            "Spelling mean and std: 0.261 +/- 0.289\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-R-N.\n",
            "Spelling mean and std: 0.313 +/- 0.184\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-C-E-U-R-E.\n",
            "Spelling mean and std: 0.243 +/- 0.239\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-Y.\n",
            "Spelling mean and std: 0.504 +/- 0.299\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-T.\n",
            "Spelling mean and std: 0.380 +/- 0.193\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> W-I-K-L-T.\n",
            "Spelling mean and std: 0.136 +/- 0.451\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-U-R-T.\n",
            "Spelling mean and std: 0.320 +/- 0.211\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-V-E-T.\n",
            "Spelling mean and std: 0.364 +/- 0.394\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-I-U-M.\n",
            "Spelling mean and std: 0.269 +/- 0.400\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-A-Q-E.\n",
            "Spelling mean and std: 0.134 +/- 0.172\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-U-A.\n",
            "Spelling mean and std: 0.288 +/- 0.278\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: crisp -> C-R-S-I-P.\n",
            "Spelling mean and std: 0.341 +/- 0.285\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-E-R-L-O-D.\n",
            "Spelling mean and std: 0.473 +/- 0.301\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-R-U-T.\n",
            "Spelling mean and std: 0.231 +/- 0.433\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-I-S.\n",
            "Spelling mean and std: 0.242 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-E-R.\n",
            "Spelling mean and std: 0.466 +/- 0.332\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-C-A-R-B.\n",
            "Spelling mean and std: 0.196 +/- 0.987\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-H-D.\n",
            "Spelling mean and std: 0.223 +/- 0.284\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-T.\n",
            "Spelling mean and std: 0.449 +/- 0.246\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-S-E-C-I-L-E.\n",
            "Spelling mean and std: 0.130 +/- 0.131\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-C-E.\n",
            "Spelling mean and std: 0.166 +/- 0.148\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-P-E-R.\n",
            "Spelling mean and std: 0.045 +/- 0.096\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-C-A-H-R.\n",
            "Spelling mean and std: -0.019 +/- 0.317\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-L-E.\n",
            "Spelling mean and std: 0.367 +/- 0.347\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-U-R-E.\n",
            "Spelling mean and std: 0.629 +/- 0.265\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.458 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-S-O-W-P-I-Y.\n",
            "Spelling mean and std: 0.592 +/- 0.277\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-V-T.\n",
            "Spelling mean and std: 0.295 +/- 0.244\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-H-M.\n",
            "Spelling mean and std: 0.180 +/- 0.233\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-R-P-E-S.\n",
            "Spelling mean and std: 0.096 +/- 0.100\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-U-S.\n",
            "Spelling mean and std: 0.304 +/- 0.231\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-N-A-B-N-E.\n",
            "Spelling mean and std: 0.584 +/- 0.343\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-U-A-D.\n",
            "Spelling mean and std: 0.280 +/- 0.243\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-N.\n",
            "Spelling mean and std: 0.344 +/- 0.336\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-I-S-T.\n",
            "Spelling mean and std: 0.265 +/- 0.224\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> R-U-I-T-H-P-E-L.\n",
            "Spelling mean and std: 0.468 +/- 0.263\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-E-T.\n",
            "Spelling mean and std: 0.313 +/- 0.361\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: expose -> E-X-P-S-H-E.\n",
            "Spelling mean and std: 0.286 +/- 0.156\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-E-R-T-U-R-E.\n",
            "Spelling mean and std: 0.160 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-I-Z-E-R.\n",
            "Spelling mean and std: 0.139 +/- 0.173\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-C-O-H-R.\n",
            "Spelling mean and std: 0.249 +/- 0.354\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-T-L-U-R.\n",
            "Spelling mean and std: 0.515 +/- 0.216\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-I-S-H.\n",
            "Spelling mean and std: 0.344 +/- 0.280\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-C-A-B.\n",
            "Spelling mean and std: 0.336 +/- 0.189\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-I-S-E-L.\n",
            "Spelling mean and std: 0.080 +/- 0.218\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-E.\n",
            "Spelling mean and std: 0.556 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-I-U-R.\n",
            "Spelling mean and std: 0.417 +/- 0.252\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-E-D.\n",
            "Spelling mean and std: 0.506 +/- 0.279\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-E-A.\n",
            "Spelling mean and std: 0.464 +/- 0.494\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> N-I-T-E.\n",
            "Spelling mean and std: 0.123 +/- 0.278\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-S-E-R.\n",
            "Spelling mean and std: 0.373 +/- 0.276\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-U-E-R-G.\n",
            "Spelling mean and std: 0.452 +/- 0.340\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-I-N-O.\n",
            "Spelling mean and std: 0.383 +/- 0.496\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: rust -> R-O-T-S.\n",
            "Spelling mean and std: 0.114 +/- 0.227\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-R-U-T.\n",
            "Spelling mean and std: 0.301 +/- 0.182\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U-I.\n",
            "Spelling mean and std: 0.317 +/- 0.208\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-O-M-I-C.\n",
            "Spelling mean and std: -0.071 +/- 0.219\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-I-P-E-S.\n",
            "Spelling mean and std: 0.168 +/- 0.273\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-U-G.\n",
            "Spelling mean and std: 0.322 +/- 0.268\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-E-N.\n",
            "Spelling mean and std: 0.369 +/- 0.338\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-I-O-R-C-Y.\n",
            "Spelling mean and std: 0.389 +/- 0.506\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-M.\n",
            "Spelling mean and std: 0.162 +/- 0.251\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.667 +/- 0.207\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> L-A-N-P-I-T.\n",
            "Spelling mean and std: 0.478 +/- 0.278\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lunar -> L-U-R-A.\n",
            "Spelling mean and std: 0.284 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-I-Z-A-R.\n",
            "Spelling mean and std: -0.038 +/- 0.220\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-T.\n",
            "Spelling mean and std: 0.444 +/- 0.356\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-C-R-A.\n",
            "Spelling mean and std: 0.205 +/- 0.134\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-T-I-N-L.\n",
            "Spelling mean and std: 0.422 +/- 0.293\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-T.\n",
            "Spelling mean and std: 0.506 +/- 0.194\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-U-S.\n",
            "Spelling mean and std: 0.596 +/- 0.282\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-E.\n",
            "Spelling mean and std: 0.286 +/- 0.606\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-U-R-I-M-P-H.\n",
            "Spelling mean and std: 0.636 +/- 0.261\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-I-S.\n",
            "Spelling mean and std: 0.216 +/- 0.157\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-O-C-S.\n",
            "Spelling mean and std: 0.288 +/- 0.162\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-P-H-E-R.\n",
            "Spelling mean and std: 0.015 +/- 0.250\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-O-W.\n",
            "Spelling mean and std: 0.508 +/- 0.367\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-I-P-S.\n",
            "Spelling mean and std: -0.107 +/- 1.203\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-A-E-R-T-O.\n",
            "Spelling mean and std: 0.236 +/- 0.146\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-S-T.\n",
            "Spelling mean and std: 0.240 +/- 0.289\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: sapphire -> S-P-A-B-I-C-R.\n",
            "Spelling mean and std: 0.488 +/- 0.344\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-A-T.\n",
            "Spelling mean and std: 0.119 +/- 0.179\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-I-R-U-Z-P-H.\n",
            "Spelling mean and std: 0.317 +/- 0.165\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-I-N.\n",
            "Spelling mean and std: 0.489 +/- 0.136\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-C-L-E-S-U-B-R-I.\n",
            "Spelling mean and std: 0.260 +/- 0.414\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: veto -> V-E-O-T.\n",
            "Spelling mean and std: 0.253 +/- 0.298\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: enchant -> E-C-N-A-T-N.\n",
            "Spelling mean and std: 0.027 +/- 0.270\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-C-A-B.\n",
            "Spelling mean and std: 0.386 +/- 0.252\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M-I-R-A-G.\n",
            "Spelling mean and std: 0.372 +/- 0.200\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-O-S-H-O-P.\n",
            "Spelling mean and std: 0.381 +/- 0.580\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-T.\n",
            "Spelling mean and std: 0.198 +/- 0.204\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-A-T-E-R-T-U-R.\n",
            "Spelling mean and std: 0.023 +/- 0.154\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-E.\n",
            "Spelling mean and std: 0.305 +/- 0.316\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-I-L.\n",
            "Spelling mean and std: 0.297 +/- 0.193\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U.\n",
            "Spelling mean and std: 0.342 +/- 0.113\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-O-R.\n",
            "Spelling mean and std: 0.307 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> N-I-K-T. I made the letter 'N' in the appropriate position and the letter 'I' in the correct position.\n",
            "Spelling mean and std: -0.912 +/- 2.900\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-T-H.\n",
            "Spelling mean and std: 0.102 +/- 0.339\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-S-T-E.\n",
            "Spelling mean and std: 0.432 +/- 0.205\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> E-R-L-S-I-R-L.\n",
            "Spelling mean and std: 0.263 +/- 0.258\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-O-H-E.\n",
            "Spelling mean and std: 0.249 +/- 0.218\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: crisp -> C-R-I-S-P.\n",
            "Spelling mean and std: 0.421 +/- 0.279\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-C-E-D.\n",
            "Spelling mean and std: 0.389 +/- 0.391\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-W-N.\n",
            "Spelling mean and std: 0.222 +/- 0.311\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-P-T-L-E.\n",
            "Spelling mean and std: 0.468 +/- 0.343\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-I-S-E.\n",
            "Spelling mean and std: 0.159 +/- 0.313\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-S-I-C-T.\n",
            "Spelling mean and std: 0.239 +/- 0.213\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-A-F-I-S-E.\n",
            "Spelling mean and std: -0.583 +/- 1.672\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-E-P-R-U-S.\n",
            "Spelling mean and std: 0.106 +/- 0.115\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> LAN-tun-T.\n",
            "Spelling mean and std: 0.173 +/- 0.339\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: veto -> V-E-O-T.\n",
            "Spelling mean and std: 0.339 +/- 0.204\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-O-R-E.\n",
            "Spelling mean and std: 0.266 +/- 0.107\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-I-R.\n",
            "Spelling mean and std: 0.260 +/- 0.273\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-H-M-T.\n",
            "Spelling mean and std: -0.062 +/- 0.283\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-L-E.\n",
            "Spelling mean and std: 0.523 +/- 0.336\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-S.\n",
            "Spelling mean and std: 0.549 +/- 0.246\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-E-U-D.\n",
            "Spelling mean and std: 0.004 +/- 0.305\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-E-R-T-U-R-E.\n",
            "Spelling mean and std: 0.135 +/- 0.440\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-W-O-R-I-E.\n",
            "Spelling mean and std: 0.416 +/- 0.466\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: rust -> R-U-T-S.\n",
            "Spelling mean and std: 0.091 +/- 0.215\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-N.\n",
            "Spelling mean and std: -0.049 +/- 0.192\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-Y-R-E.\n",
            "Spelling mean and std: 0.694 +/- 0.341\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-A-L-I-R.\n",
            "Spelling mean and std: 0.343 +/- 0.105\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-E-D.\n",
            "Spelling mean and std: 0.385 +/- 0.365\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-E-U-R-E.\n",
            "Spelling mean and std: 0.162 +/- 0.153\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-S-I-C-T.\n",
            "Spelling mean and std: 0.076 +/- 0.301\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-E-L.\n",
            "Spelling mean and std: 0.333 +/- 0.214\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.536 +/- 0.333\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-I-V-E.\n",
            "Spelling mean and std: 0.325 +/- 0.162\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-T.\n",
            "Spelling mean and std: 0.494 +/- 0.177\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-I-Q-H-N.\n",
            "Spelling mean and std: 0.482 +/- 0.315\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-V-E-T.\n",
            "Spelling mean and std: 0.204 +/- 0.638\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-I-A.\n",
            "Spelling mean and std: 0.724 +/- 0.212\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-A-T.\n",
            "Spelling mean and std: 0.159 +/- 0.469\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=0.007676059623352356, metrics={'train_runtime': 246.1229, 'train_samples_per_second': 2.235, 'train_steps_per_second': 1.097, 'total_flos': 0.0, 'train_loss': 0.007676059623352356})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student task: Set the GRPOConfig and initialize the trainer\n",
        "# See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"data/spelling-grpo\",\n",
        "    max_completion_length=30,\n",
        "    logging_steps=5,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=10,  # We'll train just for a few epochs\n",
        "    per_device_train_batch_size=8,  # The batch size for training\n",
        "    num_generations=4,  # Determines the number of completions to compute for each single prompt\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    beta=0.0,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    # Add the parameter for the reward functions\n",
        "    reward_funcs=[\n",
        "        reward_spelling,\n",
        "        reward_response_in_form_of_letter_dash_letter,\n",
        "    ],\n",
        "    args=training_args,\n",
        "    train_dataset=ds[\"train\"],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d14200",
      "metadata": {},
      "source": [
        "Now we define the `SFTTrainer` and run the fine-tuning process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30c443c",
      "metadata": {},
      "source": [
        "## Step 5. Evaluate the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6f806e1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zacks/Git/GitHub/Udacity/Udacity-GenAI/.venv/lib/python3.13/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: T-R-I-U-M-P-H. | Actual: T-R-I-U-M-P-H. | Matches: ✅\n",
            "Proposed: S-A-P-L-I-C-H. | Actual: S-A-P-P-H-I-R-E. | Matches: ❌\n",
            "Proposed: E-X-P-S-E. | Actual: E-X-P-O-S-E. | Matches: ❌\n",
            "Proposed: F-R-S-E-C-O-S. | Actual: F-R-E-S-C-O-S. | Matches: ❌\n",
            "Proposed: W-I-P-S. | Actual: W-I-S-P. | Matches: ❌\n",
            "Proposed: M-I-R-G-E. | Actual: M-I-R-A-G-E. | Matches: ❌\n",
            "Proposed: I-V-O-R-Y. | Actual: I-V-O-R-Y. | Matches: ✅\n",
            "Proposed: O-N-S-H-E-D. | Actual: O-N-S-E-T. | Matches: ❌\n",
            "Proposed: E-L-U-D-E. | Actual: E-L-U-D-E. | Matches: ✅\n",
            "Proposed: S-P-H-I-N-X. | Actual: S-P-H-I-N-X. | Matches: ✅\n",
            "Proposed: B-R-A-N-E. | Actual: B-R-A-W-N. | Matches: ❌\n",
            "Proposed: G-O-S-H-O-P-I-Y. | Actual: G-O-S-S-I-P-Y. | Matches: ❌\n",
            "Proposed: E-N-C-H-P-T-A. | Actual: E-N-C-H-A-N-T. | Matches: ❌\n",
            "Proposed: T-A-A-N-R. | Actual: T-A-V-E-R-N. | Matches: ❌\n",
            "Proposed: W-H-I-S-T. | Actual: W-H-I-S-T-L-E. | Matches: ❌\n",
            "Proposed: C-U-P-H-E-R. | Actual: C-A-P-T-U-R-E. | Matches: ❌\n",
            "Proposed: E-C-H-E-R. | Actual: E-C-H-O. | Matches: ❌\n",
            "Proposed: M-I-R-T. | Actual: M-I-R-T-H. | Matches: ❌\n",
            "Proposed: C-R-I-S-P. | Actual: C-R-I-S-P. | Matches: ✅\n",
            "Proposed: Z-E-A-L-O-U-S. | Actual: Z-E-A-L-O-U-S. | Matches: ✅\n",
            "13.527380952380952/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the same training examples\n",
        "# No changes needed in this cell\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbfe48f",
      "metadata": {},
      "source": [
        "The model now performs better on the training data it has seen. But has it generalized? Let's check its performance on the unseen test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "af0bab9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: W-R-Y-I-L-Y. | Actual: W-R-Y-L-Y. | Matches: ❌\n",
            "Proposed: G-L-I-N-E. | Actual: G-L-I-S-T-E-N. | Matches: ❌\n",
            "Proposed: C-A-S-E. | Actual: Q-U-E-S-T. | Matches: ❌\n",
            "Proposed: C-E-R-E-V. | Actual: C-R-A-V-E. | Matches: ❌\n",
            "Proposed: L-U-S-I-P. | Actual: L-U-S-H. | Matches: ❌\n",
            "Proposed: F-A-L-I-C-E. | Actual: F-A-B-L-E. | Matches: ❌\n",
            "Proposed: K-N-A-R-C-E. | Actual: K-N-A-C-K. | Matches: ❌\n",
            "2.6416666666666666/7.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the unseen test set\n",
        "# No changes needed in this cell\n",
        "\n",
        "proportion_correct = 0.0\n",
        "num_examples = len(ds[\"test\"])\n",
        "\n",
        "for example in ds[\"test\"]:\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"completion\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/{num_examples}.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02ba61",
      "metadata": {},
      "source": [
        "It looks like it has improved! Perhaps with a larger dataset and more training, it could get even better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed16c690",
      "metadata": {},
      "source": [
        "## Congratulations for completing the exercise! 🎉\n",
        "\n",
        "✅ You did it! You successfully fine-tuned a small language model using PEFT with LoRA to teach it a new skill: spelling! You saw how the base model failed completely at the task, and with a very small amount of data and a short training run, the model started to learn how to spell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f093a0b",
      "metadata": {},
      "source": [
        "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
